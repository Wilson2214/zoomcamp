{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44ab513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49c78643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.4'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "058deb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"yellow_tripdata_2019-01.csv\", nrows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecfed389",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tpep_pickup_datetime = pd.to_datetime(df.tpep_pickup_datetime)\n",
    "df.tpep_dropoff_datetime = pd.to_datetime(df.tpep_dropoff_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce3ebb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5682341a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to postgres to help generate schema in postgres language\n",
    "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b662f590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE yellow_taxi_data (\n",
      "\t\"VendorID\" BIGINT, \n",
      "\ttpep_pickup_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\ttpep_dropoff_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tpassenger_count BIGINT, \n",
      "\ttrip_distance FLOAT(53), \n",
      "\t\"RatecodeID\" BIGINT, \n",
      "\tstore_and_fwd_flag TEXT, \n",
      "\t\"PULocationID\" BIGINT, \n",
      "\t\"DOLocationID\" BIGINT, \n",
      "\tpayment_type BIGINT, \n",
      "\tfare_amount FLOAT(53), \n",
      "\textra FLOAT(53), \n",
      "\tmta_tax FLOAT(53), \n",
      "\ttip_amount FLOAT(53), \n",
      "\ttolls_amount FLOAT(53), \n",
      "\timprovement_surcharge FLOAT(53), \n",
      "\ttotal_amount FLOAT(53), \n",
      "\tcongestion_surcharge FLOAT(53)\n",
      ")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing the schema statement\n",
    "print(pd.io.sql.get_schema(df, name='yellow_taxi_data', con=engine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5dc3ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iter = pd.read_csv('yellow_tripdata_2019-01.csv', iterator=True, chunksize=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05b57a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = next(df_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09352dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f433bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tpep_pickup_datetime = pd.to_datetime(df.tpep_pickup_datetime)\n",
    "df.tpep_dropoff_datetime = pd.to_datetime(df.tpep_dropoff_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a63275",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6b82fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(n=0).to_sql(name='yellow_taxi_data', con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9bcf5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserted another chunk..., took 19.33 second\n",
      "inserted another chunk..., took 16.99 second\n",
      "inserted another chunk..., took 18.29 second\n",
      "inserted another chunk..., took 19.11 second\n",
      "inserted another chunk..., took 17.97 second\n",
      "inserted another chunk..., took 21.70 second\n",
      "inserted another chunk..., took 36.00 second\n",
      "inserted another chunk..., took 28.94 second\n",
      "inserted another chunk..., took 29.89 second\n",
      "inserted another chunk..., took 46.19 second\n",
      "inserted another chunk..., took 34.09 second\n",
      "inserted another chunk..., took 39.70 second\n",
      "inserted another chunk..., took 29.34 second\n",
      "inserted another chunk..., took 34.31 second\n",
      "inserted another chunk..., took 22.20 second\n",
      "inserted another chunk..., took 17.57 second\n",
      "inserted another chunk..., took 18.13 second\n",
      "inserted another chunk..., took 38.21 second\n",
      "inserted another chunk..., took 35.94 second\n",
      "inserted another chunk..., took 27.51 second\n",
      "inserted another chunk..., took 19.47 second\n",
      "inserted another chunk..., took 31.42 second\n",
      "inserted another chunk..., took 17.92 second\n",
      "inserted another chunk..., took 18.74 second\n",
      "inserted another chunk..., took 22.12 second\n",
      "inserted another chunk..., took 24.04 second\n",
      "inserted another chunk..., took 28.33 second\n",
      "inserted another chunk..., took 24.66 second\n",
      "inserted another chunk..., took 19.75 second\n",
      "inserted another chunk..., took 21.78 second\n",
      "inserted another chunk..., took 20.49 second\n",
      "inserted another chunk..., took 21.23 second\n",
      "inserted another chunk..., took 31.15 second\n",
      "inserted another chunk..., took 21.21 second\n",
      "inserted another chunk..., took 31.30 second\n",
      "inserted another chunk..., took 37.73 second\n",
      "inserted another chunk..., took 23.74 second\n",
      "inserted another chunk..., took 18.52 second\n",
      "inserted another chunk..., took 20.81 second\n",
      "inserted another chunk..., took 24.71 second\n",
      "inserted another chunk..., took 18.44 second\n",
      "inserted another chunk..., took 21.39 second\n",
      "inserted another chunk..., took 20.04 second\n",
      "inserted another chunk..., took 16.74 second\n",
      "inserted another chunk..., took 23.59 second\n",
      "inserted another chunk..., took 31.46 second\n",
      "inserted another chunk..., took 34.37 second\n",
      "inserted another chunk..., took 29.10 second\n",
      "inserted another chunk..., took 34.20 second\n",
      "inserted another chunk..., took 62.30 second\n",
      "inserted another chunk..., took 22.16 second\n",
      "inserted another chunk..., took 20.00 second\n",
      "inserted another chunk..., took 17.23 second\n",
      "inserted another chunk..., took 16.02 second\n",
      "inserted another chunk..., took 16.64 second\n",
      "inserted another chunk..., took 24.53 second\n",
      "inserted another chunk..., took 23.10 second\n",
      "inserted another chunk..., took 17.97 second\n",
      "inserted another chunk..., took 17.50 second\n",
      "inserted another chunk..., took 17.13 second\n",
      "inserted another chunk..., took 17.53 second\n",
      "inserted another chunk..., took 25.37 second\n",
      "inserted another chunk..., took 30.62 second\n",
      "inserted another chunk..., took 26.23 second\n",
      "inserted another chunk..., took 23.52 second\n",
      "inserted another chunk..., took 26.03 second\n",
      "inserted another chunk..., took 25.80 second\n",
      "inserted another chunk..., took 24.02 second\n",
      "inserted another chunk..., took 26.08 second\n",
      "inserted another chunk..., took 17.12 second\n",
      "inserted another chunk..., took 16.29 second\n",
      "inserted another chunk..., took 27.85 second\n",
      "inserted another chunk..., took 29.66 second\n",
      "inserted another chunk..., took 22.58 second\n",
      "inserted another chunk..., took 19.42 second\n",
      "inserted another chunk..., took 11.43 second\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m      2\u001b[0m     t_start \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m----> 4\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(df_iter)\n\u001b[1;32m      6\u001b[0m     df\u001b[38;5;241m.\u001b[39mtpep_pickup_datetime \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df\u001b[38;5;241m.\u001b[39mtpep_pickup_datetime)\n\u001b[1;32m      7\u001b[0m     df\u001b[38;5;241m.\u001b[39mtpep_dropoff_datetime \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df\u001b[38;5;241m.\u001b[39mtpep_dropoff_datetime)\n",
      "File \u001b[0;32m~/Documents/zoomcamp/zoomcamp_venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1668\u001b[0m, in \u001b[0;36mTextFileReader.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1666\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m   1667\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1668\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1669\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   1670\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/Documents/zoomcamp/zoomcamp_venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1777\u001b[0m, in \u001b[0;36mTextFileReader.get_chunk\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m   1775\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m   1776\u001b[0m     size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnrows \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_currow)\n\u001b[0;32m-> 1777\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/zoomcamp/zoomcamp_venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1748\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1741\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m     (\n\u001b[1;32m   1745\u001b[0m         index,\n\u001b[1;32m   1746\u001b[0m         columns,\n\u001b[1;32m   1747\u001b[0m         col_dict,\n\u001b[0;32m-> 1748\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1749\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1750\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1751\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/Documents/zoomcamp/zoomcamp_venv/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32mparsers.pyx:868\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    t_start = time()\n",
    "    \n",
    "    df = next(df_iter)\n",
    "    \n",
    "    df.tpep_pickup_datetime = pd.to_datetime(df.tpep_pickup_datetime)\n",
    "    df.tpep_dropoff_datetime = pd.to_datetime(df.tpep_dropoff_datetime)\n",
    "    \n",
    "    df.to_sql(name='yellow_taxi_data', con=engine, if_exists='append')\n",
    "    \n",
    "    t_end = time()\n",
    "    \n",
    "    print('inserted another chunk..., took %.2f second' %(t_end - t_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d5336b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-01-22 15:30:00--  https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.119.40, 52.217.130.248, 52.217.136.224, ...\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.119.40|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12322 (12K) [application/octet-stream]\n",
      "Saving to: ‘taxi+_zone_lookup.csv’\n",
      "\n",
      "taxi+_zone_lookup.c 100%[===================>]  12.03K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-01-22 15:30:00 (157 MB/s) - ‘taxi+_zone_lookup.csv’ saved [12322/12322]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create zones table\n",
    "!wget https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f8b398",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = pd.read_csv('taxi+_zone_lookup.csv')\n",
    "df_zones.to_sql(name='zones', con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36c55ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-01-22 15:59:44--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2019-09.csv.gz\n",
      "Resolving github.com (github.com)... 140.82.112.3\n",
      "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/b5af7693-2f26-4bd5-8854-75edeb650bae?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240122%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240122T205944Z&X-Amz-Expires=300&X-Amz-Signature=70ce7175cb22e37241a7f464404f3f5fba7e8763efdea9cfed339037095dabe4&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dgreen_tripdata_2019-09.csv.gz&response-content-type=application%2Foctet-stream [following]\n",
      "--2024-01-22 15:59:44--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/b5af7693-2f26-4bd5-8854-75edeb650bae?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240122%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240122T205944Z&X-Amz-Expires=300&X-Amz-Signature=70ce7175cb22e37241a7f464404f3f5fba7e8763efdea9cfed339037095dabe4&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dgreen_tripdata_2019-09.csv.gz&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7854533 (7.5M) [application/octet-stream]\n",
      "Saving to: ‘green_tripdata_2019-09.csv.gz’\n",
      "\n",
      "green_tripdata_2019 100%[===================>]   7.49M  23.0MB/s    in 0.3s    \n",
      "\n",
      "2024-01-22 15:59:44 (23.0 MB/s) - ‘green_tripdata_2019-09.csv.gz’ saved [7854533/7854533]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2019-09.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29f5cd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gh/2jk0_tgj2s5czzj043hknhb40000gn/T/ipykernel_56635/394022789.py:1: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  green_trips = pd.read_csv('green_tripdata_2019-09.csv')\n"
     ]
    }
   ],
   "source": [
    "green_trips = pd.read_csv('green_tripdata_2019-09.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2028ff4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE green_trips (\n",
      "\t\"VendorID\" FLOAT(53), \n",
      "\tlpep_pickup_datetime TEXT, \n",
      "\tlpep_dropoff_datetime TEXT, \n",
      "\tstore_and_fwd_flag TEXT, \n",
      "\t\"RatecodeID\" FLOAT(53), \n",
      "\t\"PULocationID\" BIGINT, \n",
      "\t\"DOLocationID\" BIGINT, \n",
      "\tpassenger_count FLOAT(53), \n",
      "\ttrip_distance FLOAT(53), \n",
      "\tfare_amount FLOAT(53), \n",
      "\textra FLOAT(53), \n",
      "\tmta_tax FLOAT(53), \n",
      "\ttip_amount FLOAT(53), \n",
      "\ttolls_amount FLOAT(53), \n",
      "\tehail_fee FLOAT(53), \n",
      "\timprovement_surcharge FLOAT(53), \n",
      "\ttotal_amount FLOAT(53), \n",
      "\tpayment_type FLOAT(53), \n",
      "\ttrip_type FLOAT(53), \n",
      "\tcongestion_surcharge FLOAT(53)\n",
      ")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.io.sql.get_schema(green_trips, name='green_trips', con=engine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2194c1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "green_trips.lpep_pickup_datetime = pd.to_datetime(green_trips.lpep_pickup_datetime)\n",
    "green_trips.lpep_dropoff_datetime = pd.to_datetime(green_trips.lpep_dropoff_datetime)\n",
    "\n",
    "green_trips.to_sql(name='green_trips', con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f883e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zoomcamp_env",
   "language": "python",
   "name": "zoomcamp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
